<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Shenghao Li</title>
  
  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Shenghao Li</name>
              </p>
              <p>I am a PhD student at <a href="https://www.sjtu.edu.cn/">SJTU</a> in Shanghai, where I work on 3D Vision, Scene Representation, and Scene Understanding.
              </p>
              <!-- <p>
                At Google I've worked on <a href="https://www.google.com/glass/start/">Glass</a>,  <a href="https://ai.googleblog.com/2014/04/lens-blur-in-new-google-camera-app.html">Lens Blur</a>, <a href="https://ai.googleblog.com/2014/10/hdr-low-light-and-high-dynamic-range.html">HDR+</a>, <a href="https://blog.google/products/google-ar-vr/introducing-next-generation-jump/">Jump</a>, <a href="https://ai.googleblog.com/2017/10/portrait-mode-on-pixel-2-and-pixel-2-xl.html">Portrait Mode</a>, <a href="https://ai.googleblog.com/2020/12/portrait-light-enhancing-portrait.html">Portrait Light</a>, and <a href="https://www.matthewtancik.com/nerf">NeRF</a>. I did my PhD at <a href="http://www.eecs.berkeley.edu/">UC Berkeley</a>, where I was advised by <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a> and funded by the <a href="http://www.nsfgrfp.org/">NSF GRFP</a>. I've received the <a href="https://www2.eecs.berkeley.edu/Students/Awards/15/">C.V. Ramamoorthy Distinguished Research Award</a> and the <a href="https://www.thecvf.com/?page_id=413#YRA">PAMI Young Researcher Award</a>.
              </p> -->
              <p style="text-align:center">
                <a href="lch94102@163.com">Email</a> &nbsp/&nbsp
                <a href="data/ShenghaoLi-CV.pdf">CV</a> &nbsp/&nbsp
                <a href="data/ShenghaoLi-bio.txt">Bio</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=Ww3F7TgAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/CVShenghaoLi">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/Merical">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/JonBarron.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/ShenghaoLi.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm interested in computer vision, machine learning, optimization, and image processing. Much of my research is about inferring the physical world (shape, motion, color, light, etc) from images. Representative papers are <span class="highlight">highlighted</span>.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
				
        <tr onmouseout="nerfslam_stop()" onmouseover="nerfslam_start()"  bgcolor="#ffffd0">
        <td style="padding:20px;width:25%;vertical-align:top;">
            <div class="one">
            <div class="two" id='nerfslam_image'><video  width="160" muted autoplay loop>
            <source src="images/nerfslam.mp4" type="video/mp4">
            Your browser does not support the video tag.
            </video></div>
            <img src='images/nerfslam.png' width="160">
            </div>
            <script type="text/javascript">
            function nerfslam_start() {
                document.getElementById('nerfslam_image').style.opacity = "1";
            }

            function nerfslam_stop() {
                document.getElementById('nerfslam_image').style.opacity = "0";
            }
            nerfslam_stop()
            </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:top">
            <a href="https://nerfslam.github.io/">
            <papertitle>Representing Unbounded Scene Online with Scale-encoded Cascaded Grid Distillation and Radiance Field Deblurring</papertitle>
            </a>
            <br>
            <strong>Shenghao Li</strong>,
            <a>Zeyang Xia</a>,
            <a>Qunfei Zhao*</a>
            <br>
            <em>IEEE Transactions on Circuits and Systems for Video Technology</em>, 2023<strong> (Under Review)</strong>.
            <br>
            <a href="https://nerfslam.github.io/">project page</a>
            <!-- / -->
            <!-- <a href="https://arxiv.org/abs/2209.14988">arXiv</a> -->
            <!-- / -->
            <p>Coming soon.</p>
        </td>
        </tr>

        <tr>
        <td style="padding:20px;width:25%;vertical-align:top">
            <img src="images/s2ld.png" width="160">
        </td>
        <td style="padding:20px;width:75%;vertical-align:top">
            <a href="https://s2ld.github.io">
            <papertitle>Sparse-to-Local-Dense Matching for Geometry-Guided Correspondence Estimation</papertitle>
            </a>
            <br>
            <strong>Shenghao Li</strong>,
            <a>Qunfei Zhao*</a>
            <a>Zeyang Xia</a>,
            <br>
            <em>IEEE Transactions on Image Processing</em>, 2023<strong>(Under Review)</strong>.
            <br>
            <a href="https://nerfslam.github.io/">project page</a>
            <!-- / -->
            <!-- <a href="https://arxiv.org/abs/2209.14988">arXiv</a> -->
            <!-- / -->
            <p>Coming soon.</p>
        </td>
        </tr>

        <tr onmouseout="ssfslam_stop()" onmouseover="ssfslam_start()"  bgcolor="#ffffd0">
        <td style="padding:20px;width:25%;vertical-align:top;">
            <div class="one">
            <div class="two" id='ssfslam_image'><video  width="160" muted autoplay loop>
            <source src="images/ssf-slam.mp4" type="video/mp4">
            Your browser does not support the video tag.
            </video></div>
            <img src='images/ssf-slam.png' width="160">
            </div>
            <script type="text/javascript">
            function ssfslam_start() {
                document.getElementById('ssfslam_image').style.opacity = "1";
            }

            function ssfslam_stop() {
                document.getElementById('ssfslam_image').style.opacity = "0";
            }
            ssfslam_stop()
            </script>
        </td>

        <td style="padding:20px;width:75%;vertical-align:top">
            <a href="https://ssf-slam.github.io">
            <papertitle>Quantized self-supervised local feature for real-time robot indirect VSLAM</papertitle>
            </a>
            <br>
            <strong>Shenghao Li</strong>,
            <a>Shuang Liu*</a>
            <a>Qunfei Zhao</a>
            <a>Qiaoyang Xia</a>,
            <br>
            <em>IEEE/ASME Transactions on Mechatronics</em>, 2022.
            <br>
            <a href="https://nerfslam.github.io/">project page</a>
            /
            <a href="https://ieeexplore.ieee.org/document/9444777/">paper</a>
            <!-- / -->
            <p>We propose a quantized self-supervised local feature for the indirect VSLAM to handle the environmental interference in robot localization tasks..</p>
        </td>
        </tr>

        <tr>
        <td style="padding:20px;width:25%;vertical-align:top">
            <img src="images/ssfeature.png" width="160">
        </td>
        <td style="padding:20px;width:75%;vertical-align:top">
            <a href="https://ssfeature.github.io">
            <papertitle>Self-supervised Feature Detection and Binary Description in Hamming Space for Mobile Platforms</papertitle>
            </a>
            <br>
            <strong>Shenghao Li</strong>,
            <a>Guibao Zhang</a>,
            <a>Qunfei Zhao*</a>
            <br>
            <em>IEEE International Conference on Real-time Computing and Robotics (RCAR)</em>, 2021.
            <br>
            <a href="https://ssfeature.github.io/">project page</a>
            /
            <a href="https://ieeexplore.ieee.org/document/9517409/">paper</a>
            <!-- / -->
            <p>We proposes a single-input multi-output model for feature extraction and a descriptor quantization approach to embedding the features into Hamming space.</p>
        </td>
        </tr>

        <tr>
        <td style="padding:20px;width:25%;vertical-align:top">
            <img src="images/drug.png" width="160">
        </td>
        <td style="padding:20px;width:75%;vertical-align:top">
            <a>
            <papertitle>Automatic Drug Box Recognition Based on Depth Camera</papertitle>
            </a>
            <br>
            <a>Changzheng Zhang</a>,
            <a>Qiaoyang Xia</a>,
            <strong>Shenghao Li</strong>,
            <a>Simeng Zhong</a>,
            <a>Shuang Liu*</a>,
            <br>
            <em>International Conference on CYBER Technology in Automation, Control, and Intelligent Systems (CYBER)</em>, 2021.
            <br>
            <a href="https://ieeexplore.ieee.org/document/9588239">paper</a>
            <p>We propose an automatic drug box detection method based on the gemoetry and color priors of the drug boxes observed from an RGB-D camera.</p>
        </td>
        </tr>

        <tr>
        <td style="padding:20px;width:25%;vertical-align:top">
            <img src="images/tghm.png" width="160">
        </td>
        <td style="padding:20px;width:75%;vertical-align:top">
            <a>
            <papertitle>Autonomous exploration and map construction of a mobile robot based on the TGHM algorithm</papertitle>
            </a>
            <br>
            <a>Shuang Liu</a>,
            <strong>Shenghao Li</strong>,
            <a>Luchao Pang</a>,
            <a>Jiahao Hu</a>,
            <a>Haoyao Chen*</a>
            <br>
            <em>Sensors</em>, 2020.
            <br>
            <a href="https://www.mdpi.com/1424-8220/20/2/490">paper</a>
            <p>We proposes proposes an autonomous exploration and map construction method based on an incremental caching topology-grid hybrid map (TGHM).</p>
        </td>
        </tr>

        <tr>
        <td style="padding:20px;width:25%;vertical-align:top">
            <img src="images/container.jpg" width="160">
        </td>
        <td style="padding:20px;width:75%;vertical-align:top">
            <a>
            <papertitle>Automatic container code localization and recognition via an efficient code detector and sequence recognition</papertitle>
            </a>
            <br>
            <strong>Shenghao Li</strong>,
            <a>Shuang Liu*</a>,
            <a>Qiaoyang Xia</a>,
            <a>Hui Wang</a>,
            <a>Haoyao Chen</a>,
            <br>
            <em>IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM)</em>, 2019.
            <br>
            <a href="https://ieeexplore.ieee.org/document/8868819">paper</a>
            <p>We propose an automatic container code localization and recognition system via an efficient code detector and a sequence recognizer.</p>
        </td>
        </tr>
					
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                 Stolen from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
