<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Shenghao Li</title>
  
  <meta name="author" content="Shenghao Li">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<!-- <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>"> -->
	<link rel="icon" href="images/ShenghaoLi.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Shenghao Li</name>
              </p>
              <p>
                I am a Ph.D. student at <a href="https://www.sjtu.edu.cn/">SJTU</a> in Shanghai, where I work on 3D Vision, Local Feature Learning, and Scene Representation and Understanding. I am advised by <a href="https://automation.sjtu.edu.cn/Qun-Fei">Prof. Qunfei Zhao</a>, and my estimated graduation date is 12, 2023.
              </p>
              <p>
                I did my MS and BS in Mechatronics at Intelligent Robot Institute, part of the <a href="https://mech.ecust.edu.cn/main.htm">School of Mechanical and Power Engineering</a> at <a href="https://www.ecust.edu.cn/">ECUST</a>. My adviser was <a href="https://mech.ecust.edu.cn/2019/0516/c11227a90188/page.htm">Prof. Shuang Liu</a>, and I worked on several projects in computer vision and robotics, including VSLAM, object detection, text recognition, etc.
              </p>
              <p>
                Since 2021, I have been working as an intern at MiniMax in the avatar group. I primarily design computer vision algorithms for 3D animatable avatars and 2D generative characters. Currently, I am working on AIGC with large vision-language models. Additionally, I interned at <a href="https://www.qualcomm.com/home">Qualcomm</a> as an AI engineer for mobile computing and at <a href="http://www.oceanring.cn/">Oceanbotech</a> as a robot vision engineer. 
              </p>
              <p>
                Please feel free to email me to discuss computer vision and robotics.
              </p>
              <p style="text-align:center">
                <a href="mailto:lch94102@163.com">Email</a> &nbsp/&nbsp
                <a href="data/resume.pdf">CV</a> &nbsp/&nbsp
                <a href="data/ShenghaoLi-bio.txt">Bio</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=Ww3F7TgAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/CVShenghaoLi">Twitter</a>
                <!-- <a href="https://twitter.com/CVShenghaoLi">Twitter</a> &nbsp/&nbsp -->
                <!-- <a href="https://github.com/Merical">Github</a> -->
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/JonBarron.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/ShenghaoLi.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm interested in computer vision, machine learning, optimization, and image processing. Much of my research is about scene reconstruction and representation from images or videos. Representative papers are <span class="highlight">highlighted</span>.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
				
        <tr onmouseout="nerfslam_stop()" onmouseover="nerfslam_start()"  bgcolor="#ffffd0">
        <td style="padding:20px;width:25%;vertical-align:top;">
            <div class="one">
            <div class="two" id='nerfslam_image'><video  width="160" muted autoplay loop>
            <source src="images/nerfslam.mp4" type="video/mp4">
            Your browser does not support the video tag.
            </video></div>
            <img src='images/nerfslam.png' width="160">
            </div>
            <script type="text/javascript">
            function nerfslam_start() {
                document.getElementById('nerfslam_image').style.opacity = "1";
            }

            function nerfslam_stop() {
                document.getElementById('nerfslam_image').style.opacity = "0";
            }
            nerfslam_stop()
            </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:top">
            <a href="https://nerfslam.github.io/">
            <papertitle>Representing Unbounded Scene Online with Scale-encoded Cascaded Grid Distillation and Radiance Field Deblurring</papertitle>
            </a>
            <br>
            <strong>Shenghao Li</strong>,
            <a>Zeyang Xia</a>,
            <a>Qunfei Zhao*</a>
            <br>
            <em>IEEE Transactions on Circuits and Systems for Video Technology</em>, 2023<strong> (Under Review)</strong>.
            <br>
            <a href="https://nerfslam.github.io/">project page</a>
            <!-- / -->
            <!-- <a href="https://arxiv.org/abs/2209.14988">arXiv</a> -->
            <!-- / -->
            <p>Coming soon.</p>
        </td>
        </tr>

        <tr bgcolor="#ffffd0">
        <td style="padding:20px;width:25%;vertical-align:top">
            <img src="images/s2ld.png" width="160">
        </td>
        <td style="padding:20px;width:75%;vertical-align:top">
            <a href="https://s2ld.github.io">
            <papertitle>Sparse-to-Local-Dense Matching for Geometry-Guided Correspondence Estimation</papertitle>
            </a>
            <br>
            <strong>Shenghao Li</strong>,
            <a>Qunfei Zhao*</a>
            <a>Zeyang Xia</a>,
            <br>
            <em>IEEE Transactions on Image Processing</em>, 2023<strong>(Under Review)</strong>.
            <br>
            <a href="https://nerfslam.github.io/">project page</a>
            <!-- / -->
            <!-- <a href="https://arxiv.org/abs/2209.14988">arXiv</a> -->
            <!-- / -->
            <p>Coming soon.</p>
        </td>
        </tr>

        <tr onmouseout="ssfslam_stop()" onmouseover="ssfslam_start()"  bgcolor="#ffffd0">
        <td style="padding:20px;width:25%;vertical-align:top;">
            <div class="one">
            <div class="two" id='ssfslam_image'><video  width="160" muted autoplay loop>
            <source src="images/ssf-slam.mp4" type="video/mp4">
            Your browser does not support the video tag.
            </video></div>
            <img src='images/ssf-slam.png' width="160">
            </div>
            <script type="text/javascript">
            function ssfslam_start() {
                document.getElementById('ssfslam_image').style.opacity = "1";
            }

            function ssfslam_stop() {
                document.getElementById('ssfslam_image').style.opacity = "0";
            }
            ssfslam_stop()
            </script>
        </td>

        <td style="padding:20px;width:75%;vertical-align:top">
            <a href="https://ssf-slam.github.io">
            <papertitle>Quantized self-supervised local feature for real-time robot indirect VSLAM</papertitle>
            </a>
            <br>
            <strong>Shenghao Li</strong>,
            <a>Shuang Liu*</a>
            <a>Qunfei Zhao</a>
            <a>Qiaoyang Xia</a>,
            <br>
            <em>IEEE/ASME Transactions on Mechatronics</em>, 2022.
            <br>
            <a href="https://nerfslam.github.io/">project page</a>
            /
            <a href="https://ieeexplore.ieee.org/document/9444777/">paper</a>
            <!-- / -->
            <p>We propose a quantized self-supervised local feature for the indirect VSLAM to handle the environmental interference in robot localization tasks..</p>
        </td>
        </tr>

        <tr>
        <td style="padding:20px;width:25%;vertical-align:top">
            <img src="images/ssfeature.png" width="160">
        </td>
        <td style="padding:20px;width:75%;vertical-align:top">
            <a href="https://ssfeature.github.io">
            <papertitle>Self-supervised Feature Detection and Binary Description in Hamming Space for Mobile Platforms</papertitle>
            </a>
            <br>
            <strong>Shenghao Li</strong>,
            <a>Guibao Zhang</a>,
            <a>Qunfei Zhao*</a>
            <br>
            <em>IEEE International Conference on Real-time Computing and Robotics (RCAR)</em>, 2021.
            <br>
            <a href="https://ssfeature.github.io/">project page</a>
            /
            <a href="https://ieeexplore.ieee.org/document/9517409/">paper</a>
            <!-- / -->
            <p>We proposes a single-input multi-output model for feature extraction and a descriptor quantization approach to embedding the features into Hamming space.</p>
        </td>
        </tr>

        <tr>
        <td style="padding:20px;width:25%;vertical-align:top">
            <img src="images/drug.png" width="160">
        </td>
        <td style="padding:20px;width:75%;vertical-align:top">
            <a>
            <papertitle>Automatic Drug Box Recognition Based on Depth Camera</papertitle>
            </a>
            <br>
            <a>Changzheng Zhang</a>,
            <a>Qiaoyang Xia</a>,
            <strong>Shenghao Li</strong>,
            <a>Simeng Zhong</a>,
            <a>Shuang Liu*</a>,
            <br>
            <em>International Conference on CYBER Technology in Automation, Control, and Intelligent Systems (CYBER)</em>, 2021.
            <br>
            <a href="https://ieeexplore.ieee.org/document/9588239">paper</a>
            <p>We propose an automatic drug box detection method based on the gemoetry and color priors of the drug boxes observed from an RGB-D camera.</p>
        </td>
        </tr>

        <tr>
        <td style="padding:20px;width:25%;vertical-align:top">
            <img src="images/tghm.png" width="160">
        </td>
        <td style="padding:20px;width:75%;vertical-align:top">
            <a>
            <papertitle>Autonomous exploration and map construction of a mobile robot based on the TGHM algorithm</papertitle>
            </a>
            <br>
            <a>Shuang Liu</a>,
            <strong>Shenghao Li</strong>,
            <a>Luchao Pang</a>,
            <a>Jiahao Hu</a>,
            <a>Haoyao Chen*</a>
            <br>
            <em>Sensors</em>, 2020.
            <br>
            <a href="https://www.mdpi.com/1424-8220/20/2/490">paper</a>
            <p>We proposes proposes an autonomous exploration and map construction method based on an incremental caching topology-grid hybrid map (TGHM).</p>
        </td>
        </tr>

        <tr>
        <td style="padding:20px;width:25%;vertical-align:top">
            <img src="images/container.jpg" width="160">
        </td>
        <td style="padding:20px;width:75%;vertical-align:top">
            <a>
            <papertitle>Automatic container code localization and recognition via an efficient code detector and sequence recognition</papertitle>
            </a>
            <br>
            <strong>Shenghao Li</strong>,
            <a>Shuang Liu*</a>,
            <a>Qiaoyang Xia</a>,
            <a>Hui Wang</a>,
            <a>Haoyao Chen</a>,
            <br>
            <em>IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM)</em>, 2019.
            <br>
            <a href="https://ieeexplore.ieee.org/document/8868819">paper</a>
            <p>We propose an automatic container code localization and recognition system via an efficient code detector and a sequence recognizer.</p>
        </td>
        </tr>
					
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                 Stolen from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
